# Is an infinite loop -> It won't be tested.

# It uses an ask_model() function inside the loop.
# Success response and failed response.

# It has a chat history saved in memory.
# It starts only with the system prompt.
# The system prompt must be added just once.
# When message is sent or model responds it must save that message.

# It will use invoke() to ask LLM.


